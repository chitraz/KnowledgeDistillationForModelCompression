{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f15aae52-9b04-484e-b903-e83b780e357c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchinfo import summary\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '../scripts') # add 'scrips' subfolder to sys path for easier import \n",
    "from Dataset import get_cifar10, get_cifar100, CIFAR100_Fine_labels, CIFAR10_labels\n",
    "from Dataset import ImageNetDataset, ConvertToPlotableImage\n",
    "from Models import get_Model\n",
    "from Utils import evaluate\n",
    "\n",
    "from models.ghostnet import ghostnet\n",
    "from models.mobilenetv2 import MobileNet_v2_x0_5, MobileNet_v2_x1_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5845ed5-0612-4cb1-a283-66c184ef41d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "40bd9e6a-652d-4f11-b362-092d66d20e57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 0.5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "===============================================================================================\n",
       "Layer (type:depth-idx)                        Output Shape              Param #\n",
       "===============================================================================================\n",
       "MobileNetV2                                   [1, 100]                  --\n",
       "├─Sequential: 1-1                             [1, 16, 16, 16]           --\n",
       "│    └─Conv2d: 2-1                            [1, 16, 16, 16]           432\n",
       "│    └─BatchNorm2d: 2-2                       [1, 16, 16, 16]           32\n",
       "│    └─ReLU: 2-3                              [1, 16, 16, 16]           --\n",
       "├─ModuleList: 1-2                             --                        --\n",
       "│    └─Sequential: 2-4                        [1, 8, 16, 16]            --\n",
       "│    │    └─InvertedResidual: 3-1             [1, 8, 16, 16]            608\n",
       "│    └─Sequential: 2-5                        [1, 12, 16, 16]           --\n",
       "│    │    └─InvertedResidual: 3-2             [1, 12, 16, 16]           1,608\n",
       "│    │    └─InvertedResidual: 3-3             [1, 12, 16, 16]           2,688\n",
       "│    └─Sequential: 2-6                        [1, 16, 8, 8]             --\n",
       "│    │    └─InvertedResidual: 3-4             [1, 16, 8, 8]             2,984\n",
       "│    │    └─InvertedResidual: 3-5             [1, 16, 8, 8]             4,352\n",
       "│    │    └─InvertedResidual: 3-6             [1, 16, 8, 8]             4,352\n",
       "│    └─Sequential: 2-7                        [1, 32, 4, 4]             --\n",
       "│    │    └─InvertedResidual: 3-7             [1, 32, 4, 4]             5,920\n",
       "│    │    └─InvertedResidual: 3-8             [1, 32, 4, 4]             14,848\n",
       "│    │    └─InvertedResidual: 3-9             [1, 32, 4, 4]             14,848\n",
       "│    │    └─InvertedResidual: 3-10            [1, 32, 4, 4]             14,848\n",
       "│    └─Sequential: 2-8                        [1, 48, 4, 4]             --\n",
       "│    │    └─InvertedResidual: 3-11            [1, 48, 4, 4]             17,952\n",
       "│    │    └─InvertedResidual: 3-12            [1, 48, 4, 4]             31,488\n",
       "│    │    └─InvertedResidual: 3-13            [1, 48, 4, 4]             31,488\n",
       "│    └─Sequential: 2-9                        [1, 80, 2, 2]             --\n",
       "│    │    └─InvertedResidual: 3-14            [1, 80, 2, 2]             40,768\n",
       "│    │    └─InvertedResidual: 3-15            [1, 80, 2, 2]             83,200\n",
       "│    │    └─InvertedResidual: 3-16            [1, 80, 2, 2]             83,200\n",
       "│    └─Sequential: 2-10                       [1, 160, 2, 2]            --\n",
       "│    │    └─InvertedResidual: 3-17            [1, 160, 2, 2]            121,760\n",
       "├─Sequential: 1-3                             [1, 1280, 2, 2]           --\n",
       "│    └─Conv2d: 2-11                           [1, 1280, 2, 2]           204,800\n",
       "│    └─BatchNorm2d: 2-12                      [1, 1280, 2, 2]           2,560\n",
       "│    └─ReLU: 2-13                             [1, 1280, 2, 2]           --\n",
       "├─AvgPool2d: 1-4                              [1, 1280, 1, 1]           --\n",
       "├─Sequential: 1-5                             [1, 100]                  --\n",
       "│    └─Linear: 2-14                           [1, 100]                  128,100\n",
       "===============================================================================================\n",
       "Total params: 812,836\n",
       "Trainable params: 812,836\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 6.54\n",
       "===============================================================================================\n",
       "Input size (MB): 0.01\n",
       "Forward/backward pass size (MB): 3.39\n",
       "Params size (MB): 3.25\n",
       "Estimated Total Size (MB): 6.65\n",
       "==============================================================================================="
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = 'MobileNetV2_x0_5'\n",
    "model = get_Model(model_name,100) # 100 class for cifar100\n",
    "\n",
    "#model = ghostnet()\n",
    "#model = torchvision.models.mobilenet_v2(100)\n",
    "#model = torchvision.models.shufflenet_v2_x1_0()\n",
    "#model = MobileNet_v2_x1_0(10)\n",
    "\n",
    "model.to(device)\n",
    "summary(model, (1,3,32,32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8dbe482c-c95d-4bba-af9e-d80c89808d55",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MobileNetV2(\n",
      "  (conv1): Sequential(\n",
      "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "  )\n",
      "  (blocks): ModuleList(\n",
      "    (0): Sequential(\n",
      "      (0): InvertedResidual(\n",
      "        (conv): Sequential(\n",
      "          (0): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "          (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "          (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (5): ReLU(inplace=True)\n",
      "          (6): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (7): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): InvertedResidual(\n",
      "        (conv): Sequential(\n",
      "          (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "          (3): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
      "          (4): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (5): ReLU(inplace=True)\n",
      "          (6): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (7): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): InvertedResidual(\n",
      "        (conv): Sequential(\n",
      "          (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "          (3): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
      "          (4): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (5): ReLU(inplace=True)\n",
      "          (6): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (7): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): InvertedResidual(\n",
      "        (conv): Sequential(\n",
      "          (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "          (3): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)\n",
      "          (4): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (5): ReLU(inplace=True)\n",
      "          (6): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (7): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): InvertedResidual(\n",
      "        (conv): Sequential(\n",
      "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "          (3): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
      "          (4): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (5): ReLU(inplace=True)\n",
      "          (6): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (7): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (2): InvertedResidual(\n",
      "        (conv): Sequential(\n",
      "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "          (3): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
      "          (4): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (5): ReLU(inplace=True)\n",
      "          (6): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (7): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): Sequential(\n",
      "      (0): InvertedResidual(\n",
      "        (conv): Sequential(\n",
      "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "          (3): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)\n",
      "          (4): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (5): ReLU(inplace=True)\n",
      "          (6): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): InvertedResidual(\n",
      "        (conv): Sequential(\n",
      "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "          (3): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
      "          (4): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (5): ReLU(inplace=True)\n",
      "          (6): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (2): InvertedResidual(\n",
      "        (conv): Sequential(\n",
      "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "          (3): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
      "          (4): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (5): ReLU(inplace=True)\n",
      "          (6): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (3): InvertedResidual(\n",
      "        (conv): Sequential(\n",
      "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "          (3): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
      "          (4): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (5): ReLU(inplace=True)\n",
      "          (6): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (4): Sequential(\n",
      "      (0): InvertedResidual(\n",
      "        (conv): Sequential(\n",
      "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "          (3): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
      "          (4): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (5): ReLU(inplace=True)\n",
      "          (6): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (7): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): InvertedResidual(\n",
      "        (conv): Sequential(\n",
      "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "          (3): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
      "          (4): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (5): ReLU(inplace=True)\n",
      "          (6): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (7): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (2): InvertedResidual(\n",
      "        (conv): Sequential(\n",
      "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "          (3): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
      "          (4): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (5): ReLU(inplace=True)\n",
      "          (6): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (7): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (5): Sequential(\n",
      "      (0): InvertedResidual(\n",
      "        (conv): Sequential(\n",
      "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "          (3): Conv2d(576, 576, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=576, bias=False)\n",
      "          (4): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (5): ReLU(inplace=True)\n",
      "          (6): Conv2d(576, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (7): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): InvertedResidual(\n",
      "        (conv): Sequential(\n",
      "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "          (3): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
      "          (4): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (5): ReLU(inplace=True)\n",
      "          (6): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (7): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (2): InvertedResidual(\n",
      "        (conv): Sequential(\n",
      "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "          (3): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
      "          (4): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (5): ReLU(inplace=True)\n",
      "          (6): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (7): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (6): Sequential(\n",
      "      (0): InvertedResidual(\n",
      "        (conv): Sequential(\n",
      "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "          (3): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
      "          (4): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (5): ReLU(inplace=True)\n",
      "          (6): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (7): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (conv2): Sequential(\n",
      "    (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=1280, out_features=100, bias=True)\n",
      "  )\n",
      "  (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "91139bb1-5102-4826-b341-0f46b9c09733",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect the basic blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "38acc7d6-2e97-4d88-b30c-f9e09651b707",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "BasicBlock                               [1, 16, 32, 32]           --\n",
       "├─Conv2d: 1-1                            [1, 16, 32, 32]           2,304\n",
       "├─BatchNorm2d: 1-2                       [1, 16, 32, 32]           32\n",
       "├─ReLU: 1-3                              [1, 16, 32, 32]           --\n",
       "├─Conv2d: 1-4                            [1, 16, 32, 32]           2,304\n",
       "├─BatchNorm2d: 1-5                       [1, 16, 32, 32]           32\n",
       "==========================================================================================\n",
       "Total params: 4,672\n",
       "Trainable params: 4,672\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 4.72\n",
       "==========================================================================================\n",
       "Input size (MB): 0.07\n",
       "Forward/backward pass size (MB): 0.52\n",
       "Params size (MB): 0.02\n",
       "Estimated Total Size (MB): 0.61\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from models.resnet import BasicBlock\n",
    "BB = BasicBlock(16,16)\n",
    "BB.to(device)\n",
    "summary(BB, (1,16,32,32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af9eff49-2f1e-4bea-97bc-946339601153",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb331af-a5da-41e3-bbdf-ac9a7f1fedc9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b871b907-3e93-4e56-8830-adf86294f372",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2a1e707c-aa37-4a1c-973e-84652aeba766",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_in = torch.rand([1,3,32,32], device= device)\n",
    "feats, logits = model(dummy_in, is_feat = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a8805582-0526-4626-8755-902a4c9dbf10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 16, 32, 32])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feats[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c6ed87c0-ef5b-47bc-8783-06f10fc9b27a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 64, 32, 32])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feats[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8f25e86a-d33a-48f3-b791-524342dd660d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 128, 16, 16])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feats[2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6e7c7746-5513-4811-a073-a68f5ddb4310",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 256, 8, 8])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feats[3].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cee49ff9-7a4d-43ce-ab2f-228e02e5c683",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 256])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feats[4].shape # after average pooling of the 64x8x8 activation maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "da6cc86b-83b5-40ef-8210-40d5867225db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 100])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aa0998d-44d4-4aca-9a7b-495f05ae0d30",
   "metadata": {},
   "source": [
    "## Load pre-train weight for model trained from-scratch on cifar100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c09da91b-8222-4404-b76f-9ae5132b8604",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model.load_state_dict(torch.load('/home/chitraz/Documents/UoS_MSc/EEEM056_Project/Experiments/saves/ResNet-14_Exp1A_182epochs_Val:64.2_2023-05-24.pth'))\n",
    "model.load_state_dict(torch.load('/home/chitraz/Documents/UoS_MSc/EEEM056_Project/Experiments/saves/WRN-40-4_pretrains_200epochs_Val:76.86_2023-06-23.pth'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8528d8e2-6210-4ca9-b5d5-a5507dacae0a",
   "metadata": {},
   "source": [
    "## define functions to pre-compute and fetch the logits and also intermediate feature tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ee66d395-46e2-4e36-a307-d8a87316d1fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for logits\n",
    "\n",
    "def PreCompute_logits(model, device, Dataloader_train):\n",
    "    MAP_ImgIdx_logits = {}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        model.to(device)\n",
    "        model.eval()\n",
    "        for _ , batch in tqdm(enumerate(Dataloader_train), total = len(Dataloader_train)):    \n",
    "            img_batch, _ , idxs = batch # unpack        \n",
    "            img_batch = img_batch.to(device) # put images on gpu mem\n",
    "            pred_logits = model(img_batch) # forward pass to get predicted logits \n",
    "\n",
    "            # save mapping as a Dict: image index -> output logits \n",
    "            for (idx, logits) in zip(idxs,pred_logits): \n",
    "\n",
    "                MAP_ImgIdx_logits[idx.item()] = logits\n",
    "\n",
    "    return MAP_ImgIdx_logits\n",
    "\n",
    "def fetch_logtis(teacher_map, idxs):\n",
    "    batch_size = len(idxs)\n",
    "    # get number of classes by checking size of logit vector\n",
    "    num_class = len(list(teacher_map.values())[0])\n",
    "\n",
    "    logits_batch = torch.zeros((batch_size, num_class), dtype=torch.float32)\n",
    "    count = 0 \n",
    "\n",
    "    for idx in idxs:\n",
    "        logits_batch[count, :] = teacher_map[idx.item()]\n",
    "        count += 1\n",
    "\n",
    "    return logits_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7c34271e-7bf1-4fa2-8260-64903d96ac0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for intermediate feature tensors\n",
    "def PreCompute_feats(model, device, Dataloader_train):\n",
    "\n",
    "    MAP_ImgIdx_feats1 = {}\n",
    "    MAP_ImgIdx_feats2 = {}\n",
    "    MAP_ImgIdx_feats3 = {}\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        model.to(device)\n",
    "        model.eval()\n",
    "        for _ , batch in tqdm(enumerate(Dataloader_train), total = len(Dataloader_train)):    \n",
    "            img_batch, _ , idxs = batch # unpack        \n",
    "            img_batch = img_batch.to(device) # put images on gpu mem\n",
    "\n",
    "            feats, _ = model(img_batch, is_feat=True, preact=True) # forward pass to get activations  \n",
    "\n",
    "            # save mapping as a Dict: image index -> feature map [16x32x32]\n",
    "            for (idx, feat) in zip(idxs,feats[1]): \n",
    "                MAP_ImgIdx_feats1[idx.item()] = feat\n",
    "            \n",
    "            # save mapping as a Dict: image index -> feature map [32x16x16]\n",
    "            for (idx, feat) in zip(idxs,feats[2]): \n",
    "                MAP_ImgIdx_feats2[idx.item()] = feat\n",
    "            \n",
    "            # save mapping as a Dict: image index -> feature map [64x8x8]\n",
    "            for (idx, feat) in zip(idxs,feats[3]): \n",
    "                MAP_ImgIdx_feats3[idx.item()] = feat\n",
    "            \n",
    "                \n",
    "    return MAP_ImgIdx_feats1, MAP_ImgIdx_feats2, MAP_ImgIdx_feats3\n",
    "\n",
    "# construct the [Batch_size x 16 x 32 x 32] tensor from relavent [16 x 32 x 32] tensors found in our pre-computed mapping \n",
    "def fetch_feats1(teacher_map, idxs):\n",
    "    batch_size = len(idxs)\n",
    "    feat_batch = torch.zeros((batch_size, 16,32,32), dtype=torch.float32)\n",
    "    count = 0\n",
    "\n",
    "    for idx in idxs:\n",
    "        feat_batch[count,:,:,:] = teacher_map[idx.item()]\n",
    "        count += 1\n",
    "\n",
    "    return feat_batch\n",
    "\n",
    "# construct the [Batch_size x 32 x 16 x 16] tensor from relavent [32 x 16 x 16] tensors found in our pre-computed mapping \n",
    "def fetch_feats2(teacher_map, idxs):\n",
    "    batch_size = len(idxs)\n",
    "    feat_batch = torch.zeros((batch_size, 32,16,16), dtype=torch.float32)\n",
    "    count = 0\n",
    "\n",
    "    for idx in idxs:\n",
    "        feat_batch[count,:,:,:] = teacher_map[idx.item()]\n",
    "        count += 1\n",
    "\n",
    "    return feat_batch\n",
    "\n",
    "# construct the [Batch_size x 64 x 8 x 8] tensor from relavent [64 x 8 x 8] tensors found in our pre-computed mapping \n",
    "def fetch_feats3(teacher_map, idxs):\n",
    "    batch_size = len(idxs)\n",
    "    feat_batch = torch.zeros((batch_size, 64,8,8), dtype=torch.float32)\n",
    "    count = 0\n",
    "\n",
    "    for idx in idxs:\n",
    "        feat_batch[count,:,:,:] = teacher_map[idx.item()]\n",
    "        count += 1\n",
    "\n",
    "    return feat_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2f27bfae-c5fa-4b0c-a817-d6fd9de261f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to completely clear model from gpu mem \n",
    "\n",
    "#del model\n",
    "#gc.collect()\n",
    "#torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c316910-a461-4dc1-8cf7-ce3cf4ea9656",
   "metadata": {},
   "source": [
    "## create dataloader for cifar 10 train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d0df4de3-2066-4aa0-bd00-19321f2656f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = get_cifar10('train', Dataset_dir = '/home/chitraz/Documents/UoS_MSc/EEEM056_Project/Experiments/dataset')\n",
    "dataloader_train  = torch.utils.data.DataLoader(dataset_train, batch_size = 128, shuffle = False, num_workers = 16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4e5b74c-d0d8-4f9c-88e8-c272e28445e6",
   "metadata": {},
   "source": [
    "## check the pre-computed features/logits "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a3429981-89ea-4ad8-8891-414d4bfe065c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████| 391/391 [00:01<00:00, 330.71it/s]\n",
      "100%|█████████████████████████████████████████████████████| 391/391 [00:01<00:00, 323.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127])\n",
      "tensor([-7.8895e-01,  4.7946e-01,  3.1003e+00, -1.5134e+00,  6.0077e-01,\n",
      "        -3.3058e+00,  7.0202e+00,  1.8596e+00,  3.1998e-01, -3.8095e+00,\n",
      "         2.9673e+00,  4.0066e+00, -1.5725e+00, -4.1587e+00,  1.8725e+00,\n",
      "         2.9815e+00, -1.2827e+00, -5.7274e+00,  2.2861e-01,  1.4532e+00,\n",
      "        -5.7127e+00, -3.3930e+00,  1.0370e+00, -4.7737e+00,  1.1495e+00,\n",
      "        -2.4301e+00,  5.8380e+00,  9.4069e-01,  1.0531e+00,  5.3321e+00,\n",
      "        -5.7588e+00, -8.3513e-01, -6.7267e-01,  3.6579e+00,  3.0679e+00,\n",
      "         3.4013e+00,  1.1074e+00, -8.0449e-01,  1.3035e+00, -3.5506e+00,\n",
      "         2.1039e+00, -5.6557e+00,  3.3593e+00,  2.1736e+00,  3.2171e+00,\n",
      "         8.5242e+00,  2.5090e+00,  3.0968e+00, -1.8176e+00, -3.6727e+00,\n",
      "         3.6754e+00,  2.9869e+00, -2.4438e+00,  3.1071e+00,  1.8081e+00,\n",
      "         3.0667e+00,  2.4415e+00,  3.7115e+00, -8.0438e+00, -1.2464e+00,\n",
      "        -3.5703e+00,  2.2682e+00,  1.8634e+00, -1.6098e+00,  1.0316e+00,\n",
      "         2.6863e+00, -1.4570e+00, -2.0515e+00, -4.9721e+00, -2.1443e+00,\n",
      "         6.6240e-01, -3.3713e+00, -2.1436e+00, -3.2523e+00, -1.1390e-03,\n",
      "        -2.8591e+00, -6.9857e+00,  4.4893e+00,  2.9425e+00,  7.1781e+00,\n",
      "         2.8020e+00, -4.8200e+00,  1.6297e+00, -1.6053e+00,  4.5582e+00,\n",
      "        -2.9424e+00, -1.4916e+00, -3.0332e+00,  6.8675e+00, -1.9708e+00,\n",
      "        -7.4237e+00, -2.6588e+00, -1.4901e+00,  1.1822e+00, -6.6655e+00,\n",
      "        -7.5224e+00,  3.4435e+00,  1.0652e+00,  4.7360e+00, -1.3297e+00],\n",
      "       device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([-0.0207, -1.0940,  2.2622,  4.0248,  3.6431, -0.1796,  5.8169,  1.6379,\n",
      "        -1.0610, -5.3673,  3.8937,  2.0011, -5.7072, -7.0327, -0.2173,  5.6054,\n",
      "        -2.0732, -2.3492, -0.4838,  4.0144, -5.7249, -2.3245,  2.4332, -3.6500,\n",
      "        -0.2347,  1.3085,  4.5225,  1.6378,  1.5160,  5.4327, -4.8142,  0.0839,\n",
      "         1.2906,  1.5104,  5.0115,  1.6703,  6.4566, -0.9538,  0.6345, -2.2469,\n",
      "         2.6911, -7.3547,  5.8456,  4.8532,  1.4531,  8.6338,  0.3644,  2.9447,\n",
      "        -5.3724, -4.5044,  5.6877,  2.0637, -1.3560,  3.1341, -0.8268,  4.8834,\n",
      "        -1.8767,  4.6487, -9.2295, -1.1201, -3.6653,  3.6569,  2.2132,  1.4270,\n",
      "         4.0557,  5.5993,  0.0132, -0.7704, -8.1426, -3.8157, -2.4778, -5.5261,\n",
      "        -1.2007, -5.3505, -1.2386, -3.7363, -6.8854,  0.3263,  1.8239,  5.2631,\n",
      "         4.0909, -6.3485,  0.4428, -0.2620,  4.2861, -3.8067, -0.3123, -1.6305,\n",
      "         8.8197, -2.0777, -7.7117, -3.9872, -2.0090, -0.5963, -5.0575, -8.1030,\n",
      "         3.2228,  3.0051,  3.7437, -4.0946], device='cuda:0')\n",
      "tensor(False, device='cuda:0')\n",
      "tensor(False, device='cuda:0')\n",
      "tensor(False, device='cuda:0')\n",
      "tensor(False, device='cuda:0')\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chitraz/miniconda3/envs/torch/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3513: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "#torch.manual_seed(0)\n",
    "#torch.use_deterministic_algorithms(True)\n",
    "#torch.cuda.manual_seed_all(42)\n",
    "\n",
    "\n",
    "# precompute logits/features\n",
    "logit_map = PreCompute_logits(model,device,dataloader_train)\n",
    "F1_map,F2_map,F3_map = PreCompute_feats(model,device,dataloader_train)\n",
    "\n",
    "model.to(device)\n",
    "model.eval()\n",
    "for itr, Batch in enumerate(dataloader_train):\n",
    "    # unpack \n",
    "    Images, _, idxs = Batch\n",
    "    Images = Images.to(device)\n",
    "    \n",
    "    # get pre computed logits \n",
    "    F1 = fetch_feats1(F1_map, idxs).to(device)\n",
    "    F2 = fetch_feats2(F2_map, idxs).to(device)\n",
    "    F3 = fetch_feats3(F3_map, idxs).to(device)\n",
    "    lo = fetch_logtis(logit_map,idxs).to(device)\n",
    "    \n",
    "    # compute it via a forward pass (to verify it the same)\n",
    "    feats, logits = model(Images, is_feat=True, preact=True) # this non-deter\n",
    "    \n",
    "    # debug\n",
    "    print(idxs) \n",
    "    print(logits[0,:]) \n",
    "    print(lo[0,:]) \n",
    "    \n",
    "    # compare the fetched pre-comuted logits/feauture to one done on the fly \n",
    "    print(torch.all(logits==lo))\n",
    "    print(torch.all(F1==feats[1]))\n",
    "    print(torch.all(F2==feats[2]))\n",
    "    print(torch.all(F3==feats[3]))\n",
    "    \n",
    "    # DIFFERENT! WHY? Oh, it maybe due to the random augmentation on each train samples! \n",
    "    \n",
    "    sys.exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d879b57d-4b23-48f2-bdb2-9bf257fae07c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "71b3efb0-2ae2-4be4-9856-b51f943e9a9c",
   "metadata": {},
   "source": [
    "## DIFFERENT RESULTS DUE TO THE RANDOM AUGMENATION OF THE TRAIN SAMPLES!!\n",
    "## Pre-computed features are for a single augmentation setting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff38e3f-3c99-48fe-930f-dfed5f132cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# try the valid of test set!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "694c1d1d-be48-4e04-98ae-7796fcc20c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_test = get_cifar10('test', Dataset_dir = '/home/chitraz/Documents/UoS_MSc/EEEM056_Project/Experiments/dataset')\n",
    "dataloader_test = torch.utils.data.DataLoader(dataset_test, batch_size = 128, shuffle = False, num_workers = 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a8c6f666-219d-402f-a812-a35fa744a396",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████| 79/79 [00:00<00:00, 304.60it/s]\n",
      "100%|███████████████████████████████████████████████████████| 79/79 [00:00<00:00, 206.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127])\n",
      "tensor([-3.9151,  3.2859,  5.1106,  3.5057,  3.3187, -2.8528,  3.6599,  4.3536,\n",
      "         1.0994, -0.7819,  6.0692,  8.3409, -9.6483, -0.8250,  2.0864, -3.0817,\n",
      "         6.1281, -6.6057, -1.3885, -0.9334, -5.8815, -1.1331,  5.5258, -5.6761,\n",
      "        -4.4374, -0.5604,  0.2083, -2.6162,  5.1664, -0.9799,  0.7374, -3.9822,\n",
      "         5.5508, -4.7515,  2.6255,  4.9151,  3.2848,  0.1814, -0.9297, -3.0498,\n",
      "         4.9346,  0.3595,  4.0384, -0.1185,  0.8446,  1.0392,  3.8778, -4.6589,\n",
      "         4.9032, -0.4116,  7.4153, -3.6619, -8.6232, -6.0684, -1.4883,  3.7341,\n",
      "        -5.7435, -3.1546, -4.1557, -4.8827, -8.3375,  5.4998,  2.4171,  1.0654,\n",
      "        10.5289,  3.7911,  5.8147,  1.2046, -8.7986, -5.0648, -2.9218, -5.8378,\n",
      "         5.3255,  2.7087,  2.2463,  5.3651, -2.5163,  0.3625,  0.3737,  2.1174,\n",
      "         1.1683, -2.3564,  0.2590, -5.9623, -2.1248, -7.2973,  6.0736,  2.1586,\n",
      "         1.2115, -4.8545,  0.3322,  1.1320,  1.9500,  4.7499, -5.7463, -4.3525,\n",
      "        -4.1724,  1.8303,  3.9565, -3.0797], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([-3.9151,  3.2859,  5.1106,  3.5057,  3.3187, -2.8528,  3.6599,  4.3536,\n",
      "         1.0994, -0.7819,  6.0692,  8.3409, -9.6483, -0.8250,  2.0864, -3.0817,\n",
      "         6.1281, -6.6057, -1.3885, -0.9334, -5.8815, -1.1331,  5.5258, -5.6761,\n",
      "        -4.4374, -0.5604,  0.2083, -2.6162,  5.1664, -0.9799,  0.7374, -3.9822,\n",
      "         5.5508, -4.7515,  2.6255,  4.9151,  3.2848,  0.1814, -0.9297, -3.0498,\n",
      "         4.9346,  0.3595,  4.0384, -0.1185,  0.8446,  1.0392,  3.8778, -4.6589,\n",
      "         4.9032, -0.4116,  7.4153, -3.6619, -8.6232, -6.0684, -1.4883,  3.7341,\n",
      "        -5.7435, -3.1546, -4.1557, -4.8827, -8.3375,  5.4998,  2.4171,  1.0654,\n",
      "        10.5289,  3.7911,  5.8147,  1.2046, -8.7986, -5.0648, -2.9218, -5.8378,\n",
      "         5.3255,  2.7087,  2.2463,  5.3651, -2.5163,  0.3625,  0.3737,  2.1174,\n",
      "         1.1683, -2.3564,  0.2590, -5.9623, -2.1248, -7.2973,  6.0736,  2.1586,\n",
      "         1.2115, -4.8545,  0.3322,  1.1320,  1.9500,  4.7499, -5.7463, -4.3525,\n",
      "        -4.1724,  1.8303,  3.9565, -3.0797], device='cuda:0')\n",
      "tensor(True, device='cuda:0')\n",
      "tensor(False, device='cuda:0')\n",
      "tensor(False, device='cuda:0')\n",
      "tensor(False, device='cuda:0')\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "logit_map = PreCompute_logits(model,device,dataloader_test)\n",
    "F1_map,F2_map,F3_map = PreCompute_feats(model,device,dataloader_test)\n",
    "\n",
    "model.to(device)\n",
    "model.eval()\n",
    "for itr, Batch in enumerate(dataloader_test):\n",
    "    # unpack \n",
    "    Images, _, idxs = Batch\n",
    "    Images = Images.to(device)\n",
    "    \n",
    "    # get pre computed logits \n",
    "    F1 = fetch_feats1(F1_map, idxs).to(device)\n",
    "    F2 = fetch_feats2(F2_map, idxs).to(device)\n",
    "    F3 = fetch_feats3(F3_map, idxs).to(device)\n",
    "    lo = fetch_logtis(logit_map,idxs).to(device)\n",
    "      \n",
    "    # compute it via a forward pass\n",
    "    feats, logits = model(Images, is_feat=True, preact=False) \n",
    "\n",
    "    # debug\n",
    "    print(idxs) \n",
    "    print(logits[0,:]) \n",
    "    print(lo[0,:]) \n",
    "    \n",
    "    # check \n",
    "    print(torch.all(logits==lo))\n",
    "    print(torch.all(F1==feats[1]))\n",
    "    print(torch.all(F2==feats[2]))\n",
    "    print(torch.all(F3==feats[3]))\n",
    "    \n",
    "    sys.exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a83a00-33e0-4216-853c-ad59e4228f32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df0edd59-7b39-492d-a801-10fdd7c14cdb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "864ff118-a8c2-4e9c-b191-2cc73501499e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "475a9980-c49b-4c52-a56e-265e83318ba5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 64, 8, 8])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feats[-2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e9d54a79-79ca-4d5f-9a97-c6d3e8d69173",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 64, 1, 1])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.avgpool(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "fb871608-7c8c-4226-999f-3c80da4d32cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=64, out_features=100, bias=True)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4348676-025b-448f-8e7e-0b5730a4829e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e7f28b-2873-4ffa-a8b6-9fa2c593311e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85618c73-248b-4b66-a592-9884e9509417",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb0ab787-00ef-482d-af50-39f396bd2620",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:torch] *",
   "language": "python",
   "name": "conda-env-torch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "toc-autonumbering": true,
  "toc-showcode": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
